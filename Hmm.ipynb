{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49be3a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/ridoy/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/ridoy/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9706005879882402\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           .       1.00      1.00      1.00       334\n",
      "         ADJ       0.88      0.94      0.91       140\n",
      "         ADP       0.97      0.96      0.97       283\n",
      "         ADV       0.85      0.87      0.86       124\n",
      "        CONJ       1.00      1.00      1.00        84\n",
      "         DET       1.00      0.99      0.99       295\n",
      "        NOUN       0.97      0.98      0.98       483\n",
      "         NUM       0.95      0.95      0.95        21\n",
      "        PRON       0.99      1.00      0.99       160\n",
      "         PRT       0.92      0.93      0.92        70\n",
      "        VERB       0.99      0.96      0.98       370\n",
      "           X       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.97      2381\n",
      "   macro avg       0.96      0.96      0.96      2381\n",
      "weighted avg       0.97      0.97      0.97      2381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# SETUP: Required Imports\n",
    "# ======================\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ======================\n",
    "# DOWNLOAD NLTK DATA\n",
    "# ======================\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "# ======================\n",
    "# DATA PREPARATION\n",
    "# ======================\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Load Brown corpus with universal POS tags\n",
    "tagged_sents = brown.tagged_sents(tagset='universal')\n",
    "\n",
    "# Prepare vocabulary and tags\n",
    "word_counts = defaultdict(int)\n",
    "tag_counts = defaultdict(int)\n",
    "\n",
    "for sent in tagged_sents:\n",
    "    for word, tag in sent:\n",
    "        word_counts[word.lower()] += 1\n",
    "        tag_counts[tag] += 1\n",
    "\n",
    "# Create mappings\n",
    "vocab = list(word_counts.keys())\n",
    "tags = list(tag_counts.keys())\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "idx2tag = {i: t for t, i in tag2idx.items()}\n",
    "\n",
    "# MODEL INITIALIZATION\n",
    "\n",
    "n_states = len(tags)\n",
    "n_observations = len(vocab)\n",
    "\n",
    "# Uniform initial probabilities\n",
    "start_prob = np.ones(n_states) / n_states\n",
    "\n",
    "# Initialize transition and emission matrices\n",
    "trans_counts = np.zeros((n_states, n_states))\n",
    "emit_counts = np.zeros((n_states, n_observations))\n",
    "\n",
    "# ======================\n",
    "# PARAMETER ESTIMATION\n",
    "# ======================\n",
    "for sent in tagged_sents:\n",
    "    prev_tag = None\n",
    "    for word, tag in sent:\n",
    "        word_idx = word2idx[word.lower()]\n",
    "        tag_idx = tag2idx[tag]\n",
    "\n",
    "        if prev_tag is None:\n",
    "            start_prob[tag_idx] += 1\n",
    "        else:\n",
    "            trans_counts[prev_tag, tag_idx] += 1\n",
    "\n",
    "        emit_counts[tag_idx, word_idx] += 1\n",
    "        prev_tag = tag_idx\n",
    "\n",
    "# Normalize to probabilities\n",
    "start_prob /= start_prob.sum()\n",
    "trans_mat = trans_counts / trans_counts.sum(axis=1, keepdims=True)\n",
    "emit_mat = emit_counts / emit_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "# ======================\n",
    "# VITERBI DECODER\n",
    "# ======================\n",
    "def viterbi_decode(sentence, tags, start_prob, trans_mat, emit_mat):\n",
    "    obs_seq = [word2idx.get(w.lower(), 0) for w in sentence.split()]\n",
    "    T = len(obs_seq)\n",
    "    N = len(tags)\n",
    "\n",
    "    delta = np.zeros((T, N))\n",
    "    psi = np.zeros((T, N), dtype=int)\n",
    "\n",
    "    delta[0] = start_prob * emit_mat[:, obs_seq[0]]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            trans_probs = delta[t - 1] * trans_mat[:, j]\n",
    "            psi[t, j] = np.argmax(trans_probs)\n",
    "            delta[t, j] = np.max(trans_probs) * emit_mat[j, obs_seq[t]]\n",
    "\n",
    "    path = np.zeros(T, dtype=int)\n",
    "    path[-1] = np.argmax(delta[-1])\n",
    "    for t in range(T - 2, -1, -1):\n",
    "        path[t] = psi[t + 1, path[t + 1]]\n",
    "\n",
    "    return [tags[i] for i in path]\n",
    "\n",
    "# ======================\n",
    "# EVALUATION METRICS\n",
    "# ======================\n",
    "def evaluate_model(test_sents, word2idx, tag2idx, tags, start_prob, trans_mat, emit_mat):\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for sent in test_sents:\n",
    "        words = [w for w, t in sent]\n",
    "        true_tags = [t for w, t in sent]\n",
    "        pred_tags = viterbi_decode(' '.join(words), tags, start_prob, trans_mat, emit_mat)\n",
    "\n",
    "        y_true.extend(true_tags)\n",
    "        y_pred.extend(pred_tags)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# ======================\n",
    "# SAMPLE TEST\n",
    "# ======================\n",
    "# Split into train/test if desired\n",
    "test_sents = tagged_sents[-100:]  # last 100 sentences as test\n",
    "evaluate_model(test_sents, word2idx, tag2idx, tags, start_prob, trans_mat, emit_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3deafe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
